{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22821dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "import numpy as np\n",
    "import gensim.downloader\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a63422a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8be5afe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "wv = gensim.downloader.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e2bed1",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fad4bb",
   "metadata": {},
   "source": [
    "## Doyle & Christie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca6479f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_Doyle_Christie():\n",
    "    data = pd.read_csv(\"Doyle_Christie_dataset/train.csv\")\n",
    "    data = data.drop(columns=['Unnamed: 0',])\n",
    "    data['labels'] = data['author'].apply(lambda x: 0 if x == 'Doyle' else 1)\n",
    "    \n",
    "    test_data = pd.read_csv(\"Doyle_Christie_dataset/test.csv\")\n",
    "    test_data = test_data.drop(columns=['Unnamed: 0',])\n",
    "    test_data['labels'] = test_data['author'].apply(lambda x: 0 if x == 'Doyle' else 1)\n",
    "    \n",
    "    return data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "030b127d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dc, test_dc = process_Doyle_Christie()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04696c4",
   "metadata": {},
   "source": [
    "## Letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09bb1b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_Letters():\n",
    "    old_eng = pd.read_csv('old_english_dataset.csv')\n",
    "    old_eng = old_eng.drop(columns=['Unnamed: 0',])\n",
    "    old_eng['labels'] = old_eng['gender'].apply(lambda x: 0 if x == 'f' else 1)\n",
    "    \n",
    "    equal = old_eng[old_eng['labels'] == 1].sample(n = 2806)\n",
    "    train_old_eng = pd.concat([equal, old_eng[old_eng['labels'] == 0]], ignore_index=True)\n",
    "    \n",
    "    women = train_old_eng[train_old_eng['labels'] == 0]\n",
    "    men = train_old_eng[train_old_eng['labels'] == 1]\n",
    "    \n",
    "    test_women = women.sample(frac=0.1)\n",
    "    train_women = women.drop(test_women.index)\n",
    "    test_men = men.sample(frac=0.1)\n",
    "    train_men = men.drop(test_men.index)\n",
    "    \n",
    "    train_old_eng = pd.concat([train_women, train_men], ignore_index=True)\n",
    "    test_old_eng = pd.concat([test_women, test_men], ignore_index=True)\n",
    "    \n",
    "    return train_old_eng, test_old_eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95e2da98",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_letters, test_letters = process_Letters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8123a8f7",
   "metadata": {},
   "source": [
    "## Modern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d348e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_Modern():\n",
    "    data = pd.read_csv(\"Modern_dataset/train.csv\")\n",
    "    data = data.drop(columns=['Unnamed: 0',])\n",
    "    data['labels'] = data['gender'].apply(lambda x: 0 if x == 'f' else 1)\n",
    "    \n",
    "    train_data = pd.concat([data[data['labels'] == 1].sample(n=30941), data[data['labels']==0]], \n",
    "                       ignore_index=True)\n",
    "    \n",
    "    test = pd.read_csv(\"Modern_dataset/test.csv\")\n",
    "    test = test.drop(columns=['Unnamed: 0',])\n",
    "    test['labels'] = test['gender'].apply(lambda x: 0 if x == 'f' else 1)\n",
    "    \n",
    "    test_data = pd.concat([test[test['labels'] == 0].sample(n=5000), test[test['labels'] == 1].sample(n=5000)], \n",
    "                      ignore_index=True)\n",
    "    \n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e623807",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_modern, test_modern = process_Modern()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e6b099",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "997b94fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pairs(data, labels, column):\n",
    "    doyle = data[data[column] == labels[0]]\n",
    "    christie = data[data[column] == labels[1]]\n",
    "    \n",
    "    doyle_true = doyle.sample(frac = 0.5)\n",
    "    doyle_false = doyle.drop(doyle_true.index)\n",
    "    \n",
    "    christie_true = christie.sample(frac = 0.5)\n",
    "    christie_false = christie.drop(christie_true.index)\n",
    "    \n",
    "    doyle_left = doyle_true.sample(frac=0.5)\n",
    "    doyle_right = doyle_true.drop(doyle_left.index)\n",
    "    \n",
    "    christie_left = christie_true.sample(frac=0.5)\n",
    "    christie_right = christie_true.drop(christie_left.index)\n",
    "    \n",
    "    false_pair_data = pd.DataFrame({'sentence1':list(doyle_false['sentence']), \n",
    "                                'sentence2':list(christie_false['sentence']),\n",
    "                               'labels':['0' for i in range(len(doyle_false))]})\n",
    "    \n",
    "    doyle_pair_data = pd.DataFrame({'sentence1':list(doyle_left['sentence']), \n",
    "                                'sentence2':list(doyle_right['sentence']),\n",
    "                               'labels':['1' for i in range(len(doyle_right))]})\n",
    "    \n",
    "    christie_pair_data = pd.DataFrame({'sentence1':list(christie_left['sentence']), \n",
    "                                'sentence2':list(christie_right['sentence']),\n",
    "                               'labels':['1' for i in range(len(christie_right))]})\n",
    "    \n",
    "    pairs = pd.concat([false_pair_data, doyle_pair_data, christie_pair_data], ignore_index=True)\n",
    "    \n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99f78ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# это код из статьи\n",
    "\n",
    "def process_dataset(dataset, model, vocabulary, inverse_vocabulary):\n",
    "    \n",
    "    processed_dataset = []\n",
    "    \n",
    "    for index, row in tqdm(dataset.iterrows()):\n",
    "        pair = []\n",
    "        questions = [row['sentence1'], row['sentence2']]\n",
    "        for question in questions:\n",
    "\n",
    "            q2n = []  # q2n -> question numbers representation\n",
    "            for word in question.lower().split():\n",
    "\n",
    "                # Check for unwanted words\n",
    "                if word not in model.key_to_index.keys():\n",
    "                    continue\n",
    "\n",
    "                if word not in vocabulary:\n",
    "                    vocabulary[word] = len(inverse_vocabulary)\n",
    "                    q2n.append(len(inverse_vocabulary))\n",
    "                    inverse_vocabulary.append(word)\n",
    "                else:\n",
    "                    q2n.append(vocabulary[word])\n",
    "            \n",
    "            pair.append(torch.tensor(q2n))\n",
    "        processed_dataset.append(pair)\n",
    "                    \n",
    "    return vocabulary, inverse_vocabulary, processed_dataset\n",
    "\n",
    "\n",
    "def prepare_embeddings(model, train, valid, test):\n",
    "    vocabulary = dict()\n",
    "    inverse_vocabulary = ['<unk>']\n",
    "\n",
    "    # Iterate over the questions only of both training and test datasets\n",
    "    vocabulary, inverse_vocabulary, processed_train = process_dataset(train, model, vocabulary, inverse_vocabulary)\n",
    "    vocabulary, inverse_vocabulary, processed_valid = process_dataset(valid, model, vocabulary, inverse_vocabulary)\n",
    "    vocabulary, inverse_vocabulary, processed_test = process_dataset(test, model, vocabulary, inverse_vocabulary)\n",
    "\n",
    "    embedding_dim = model.vector_size\n",
    "    embeddings = 1 * np.random.randn(len(vocabulary) + 1, embedding_dim)  # This will be the embedding matrix\n",
    "    embeddings[0] = 0  # So that the padding will be ignored\n",
    "\n",
    "    # Build the embedding matrix\n",
    "    for word, index in vocabulary.items():\n",
    "        if word in model.key_to_index.keys():\n",
    "            embeddings[index] = model.word_vec(word)\n",
    "\n",
    "    return embeddings, embedding_dim, processed_train, processed_valid, processed_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cdda47d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# это код из тетрадки Семена Сорокина?\n",
    "\n",
    "def padding(sequence, sequence_length=60):\n",
    "\n",
    "    if len(sequence)< sequence_length:\n",
    "        add_pad = sequence_length - len(sequence)\n",
    "        return torch.cat((sequence, torch.tensor([0,]*add_pad)), 0)\n",
    "    else:\n",
    "        return sequence[:sequence_length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3bc8c411",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PairDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.labels = torch.tensor([int(l) for l in labels], dtype=torch.int64)\n",
    "        self.left = [torch.tensor(row[0], dtype=torch.int64) for row in data]\n",
    "        self.right = [torch.tensor(row[1], dtype=torch.int64) for row in data]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        label = self.labels[idx]\n",
    "        left = self.left[idx]\n",
    "        right = self.right[idx]\n",
    "\n",
    "        return left, right, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c9d20d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseClassifier(torch.nn.Module):\n",
    "    def __init__(self, matrix, lstm_size): \n",
    "        super().__init__()\n",
    "        \n",
    "        self.emb_layer = torch.nn.Embedding.from_pretrained(torch.Tensor(matrix))\n",
    "        self.LSTM = torch.nn.LSTM(300, lstm_size, num_layers=2, bidirectional=False)\n",
    "        \n",
    "        \n",
    "    def forward(self, left, right):\n",
    "\n",
    "        encoded_left = self.emb_layer(left)\n",
    "        encoded_right = self.emb_layer(right)\n",
    "        \n",
    "        out_left, _ = self.LSTM(encoded_left)\n",
    "        out_right, _ = self.LSTM(encoded_right)\n",
    "        \n",
    "        distance = torch.abs(torch.add(out_left, out_right.neg())).sum(axis=(1, 2)).neg().exp()\n",
    "\n",
    "        return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "453129ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# это код с ниса Семена Сорокина\n",
    "\n",
    "def train_model(model, criterion, optimizer, epochs, train_loader, valid_loader):\n",
    "    \n",
    "    model = model.to(device)    \n",
    "    criterion = criterion.to(device)\n",
    "\n",
    "    losses = []\n",
    "    best_test_loss = 10.\n",
    "\n",
    "    test_f1 = []\n",
    "\n",
    "    for n_epoch in tqdm(range(epochs)):\n",
    "\n",
    "        train_losses = []\n",
    "        test_losses = []\n",
    "\n",
    "        model.train()\n",
    "\n",
    "        for left, right, y in train_loader:\n",
    "\n",
    "            left = left.to(device)\n",
    "            right = right.to(device)\n",
    "            y = torch.tensor(y, dtype=torch.float32)\n",
    "            y = y.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            pred = model(left, right)\n",
    "            loss = criterion(pred, y)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_losses.append(loss.item())\n",
    "            losses.append(loss.item())\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        for left, right, y in valid_loader:\n",
    "\n",
    "            left = left.to(device)\n",
    "            right = right.to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "\n",
    "                pred = model(left, right)\n",
    "                pred = pred.cpu()\n",
    "                \n",
    "                y = y.cpu()\n",
    "\n",
    "                loss = criterion(pred, y)\n",
    "                test_losses.append(loss.item())\n",
    "\n",
    "        mean_test_loss = np.mean(test_losses)\n",
    "\n",
    "        print()\n",
    "        print('Losses: train - {:.3f}, test - {:.3f}'.format(np.mean(train_losses), mean_test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e3a497d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_accuracy(model, test_loader):\n",
    "    test_targets = []\n",
    "    test_losses = []\n",
    "    criterion = torch.nn.MSELoss().to(device)\n",
    "    logits = []\n",
    "\n",
    "    for left, right, y in test_loader:\n",
    "\n",
    "        left = left.to(device)\n",
    "        right = right.to(device)\n",
    "        y = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            pred = torch.squeeze(model(left, right))\n",
    "            pred = pred.cpu()\n",
    "            logits.append(pred)\n",
    "            test_targets.append(y)\n",
    "\n",
    "            loss = criterion(pred, y)\n",
    "            test_losses.append(loss.item())\n",
    "\n",
    "            \n",
    "    double_pred_scores = [[1-s, s] for s in np.concatenate(logits).squeeze()]\n",
    "    print('logloss: ', log_loss(y_pred = double_pred_scores, y_true = torch.cat(test_targets)))\n",
    "    \n",
    "    accuracy = [round(s) == y for s, y in zip(np.concatenate(logits).squeeze(), torch.cat(test_targets))]\n",
    "    print('accuracy: ', accuracy.count(True)/len(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1711e1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Siamese_pipeline(data, test_data, labels, column, wv):\n",
    "    \n",
    "    # turn into dataset with pairs\n",
    "    train_pairs = make_pairs(data=data, labels=labels, column=column)\n",
    "    test_pairs = make_pairs(data=test_data, labels=labels, column=column)\n",
    "    valid_pairs = train_pairs.sample(frac = 0.1)\n",
    "    train_pairs = train_pairs.drop(valid_pairs.index)\n",
    "    \n",
    "    # embeddings\n",
    "    embeddings, embedding_dim, proc_train, proc_valid, proc_test = prepare_embeddings(model=wv, \n",
    "                                                                                 train=train_pairs, \n",
    "                                                                                 valid=valid_pairs,\n",
    "                                                                                 test=test_pairs)\n",
    "    # padding examples\n",
    "    proc_train = [[padding(row[0]), padding(row[1])] for row in proc_train]\n",
    "    proc_valid = [[padding(row[0]), padding(row[1])] for row in proc_valid]\n",
    "    proc_test = [[padding(row[0]), padding(row[1])] for row in proc_test]\n",
    "    \n",
    "    \n",
    "    # prepare dataloaders\n",
    "    train_dataset = PairDataset(proc_train, train_pairs['labels'])\n",
    "    train_loader = DataLoader(train_dataset, batch_size=64)\n",
    "\n",
    "    valid_dataset = PairDataset(proc_valid, valid_pairs['labels'])\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=64)\n",
    "\n",
    "    test_dataset = PairDataset(proc_test, test_pairs['labels'])\n",
    "    test_loader = DataLoader(test_dataset, batch_size=64)\n",
    "    \n",
    "    model = SiameseClassifier(embeddings, 100)\n",
    "    criterion = torch.nn.MSELoss().to(device)\n",
    "    optimizer = torch.optim.Adam(params=model.parameters())\n",
    "    \n",
    "    train_model(model=model, \n",
    "                criterion=criterion, \n",
    "                optimizer=optimizer, \n",
    "                epochs=30, \n",
    "                train_loader=train_loader,\n",
    "                valid_loader=valid_loader)\n",
    "    \n",
    "    test_accuracy(model=model, test_loader=test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd07267f",
   "metadata": {},
   "source": [
    "# main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b6eda599",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9efb6109eac429497cea52506783a3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33c5efbc3f54441daa975f20935db6df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "958cf2dae19643eabcb2f55c14a0f5fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1718761/1914772776.py:48: DeprecationWarning: Call to deprecated `word_vec` (Use get_vector instead).\n",
      "  embeddings[index] = model.word_vec(word)\n",
      "/tmp/ipykernel_1718761/3629608360.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.left = [torch.tensor(row[0], dtype=torch.int64) for row in data]\n",
      "/tmp/ipykernel_1718761/3629608360.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.right = [torch.tensor(row[1], dtype=torch.int64) for row in data]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e71b8ea504574a539d5b1a807a47d129",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1718761/853187508.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(y, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Losses: train - 0.339, test - 0.356\n",
      "\n",
      "Losses: train - 0.515, test - 0.506\n",
      "\n",
      "Losses: train - 0.232, test - 0.394\n",
      "\n",
      "Losses: train - 0.517, test - 0.500\n",
      "\n",
      "Losses: train - 0.236, test - 0.402\n",
      "\n",
      "Losses: train - 0.510, test - 0.418\n",
      "\n",
      "Losses: train - 0.260, test - 0.399\n",
      "\n",
      "Losses: train - 0.520, test - 0.477\n",
      "\n",
      "Losses: train - 0.225, test - 0.410\n",
      "\n",
      "Losses: train - 0.501, test - 0.332\n",
      "\n",
      "Losses: train - 0.297, test - 0.401\n",
      "\n",
      "Losses: train - 0.407, test - 0.364\n",
      "\n",
      "Losses: train - 0.367, test - 0.364\n",
      "\n",
      "Losses: train - 0.598, test - 0.501\n",
      "\n",
      "Losses: train - 0.349, test - 0.334\n",
      "\n",
      "Losses: train - 0.301, test - 0.374\n",
      "\n",
      "Losses: train - 0.269, test - 0.411\n",
      "\n",
      "Losses: train - 0.378, test - 0.387\n",
      "\n",
      "Losses: train - 0.307, test - 0.422\n",
      "\n",
      "Losses: train - 0.285, test - 0.429\n",
      "\n",
      "Losses: train - 0.426, test - 0.348\n",
      "\n",
      "Losses: train - 0.252, test - 0.383\n",
      "\n",
      "Losses: train - 0.227, test - 0.435\n",
      "\n",
      "Losses: train - 0.372, test - 0.376\n",
      "\n",
      "Losses: train - 0.259, test - 0.408\n",
      "\n",
      "Losses: train - 0.375, test - 0.379\n",
      "\n",
      "Losses: train - 0.262, test - 0.412\n",
      "\n",
      "Losses: train - 0.359, test - 0.386\n",
      "\n",
      "Losses: train - 0.208, test - 0.404\n",
      "\n",
      "Losses: train - 0.255, test - 0.443\n",
      "logloss:  1.7129031621697757\n",
      "accuracy:  0.507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1718761/3412259436.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(y, dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "Siamese_pipeline(data=train_dc, test_data=test_dc, labels=['Doyle', 'Christie'], column='author', wv=wv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "34c27958",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37534d165aa84454b539f7b9798d8459",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6522ca61db07448182a22f392aad990b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2374aca840ac4564aba28ab67a92a494",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1718761/1914772776.py:48: DeprecationWarning: Call to deprecated `word_vec` (Use get_vector instead).\n",
      "  embeddings[index] = model.word_vec(word)\n",
      "/tmp/ipykernel_1718761/3629608360.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.left = [torch.tensor(row[0], dtype=torch.int64) for row in data]\n",
      "/tmp/ipykernel_1718761/3629608360.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.right = [torch.tensor(row[1], dtype=torch.int64) for row in data]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d17255e101df4dd58dd60eb96964e2df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1718761/853187508.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(y, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Losses: train - 0.509, test - 0.484\n",
      "\n",
      "Losses: train - 0.508, test - 0.473\n",
      "\n",
      "Losses: train - 0.437, test - 0.263\n",
      "\n",
      "Losses: train - 0.519, test - 0.480\n",
      "\n",
      "Losses: train - 0.410, test - 0.253\n",
      "\n",
      "Losses: train - 0.479, test - 0.302\n",
      "\n",
      "Losses: train - 0.473, test - 0.294\n",
      "\n",
      "Losses: train - 0.507, test - 0.440\n",
      "\n",
      "Losses: train - 0.328, test - 0.269\n",
      "\n",
      "Losses: train - 0.537, test - 0.460\n",
      "\n",
      "Losses: train - 0.345, test - 0.259\n",
      "\n",
      "Losses: train - 0.516, test - 0.415\n",
      "\n",
      "Losses: train - 0.304, test - 0.280\n",
      "\n",
      "Losses: train - 0.519, test - 0.410\n",
      "\n",
      "Losses: train - 0.310, test - 0.276\n",
      "\n",
      "Losses: train - 0.523, test - 0.407\n",
      "\n",
      "Losses: train - 0.314, test - 0.274\n",
      "\n",
      "Losses: train - 0.535, test - 0.438\n",
      "\n",
      "Losses: train - 0.346, test - 0.263\n",
      "\n",
      "Losses: train - 0.516, test - 0.395\n",
      "\n",
      "Losses: train - 0.318, test - 0.273\n",
      "\n",
      "Losses: train - 0.503, test - 0.384\n",
      "\n",
      "Losses: train - 0.328, test - 0.272\n",
      "\n",
      "Losses: train - 0.517, test - 0.355\n",
      "\n",
      "Losses: train - 0.327, test - 0.261\n",
      "\n",
      "Losses: train - 0.439, test - 0.258\n",
      "\n",
      "Losses: train - 0.346, test - 0.254\n",
      "\n",
      "Losses: train - 0.342, test - 0.255\n",
      "\n",
      "Losses: train - 0.339, test - 0.254\n",
      "\n",
      "Losses: train - 0.326, test - 0.254\n",
      "logloss:  0.7559771770400375\n",
      "accuracy:  0.5160142348754448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1718761/3412259436.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(y, dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "Siamese_pipeline(data=train_letters, test_data=test_letters, labels=['f', 'm'], column='gender', wv=wv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "261d4de9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbfb21c20e48497d8a7d3dd7c2f89a9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "902427a9f1e74b91ae82fba6f02fea68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "104cc4b433334a888362fb3649f2f703",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2195305/1914772776.py:48: DeprecationWarning: Call to deprecated `word_vec` (Use get_vector instead).\n",
      "  embeddings[index] = model.word_vec(word)\n",
      "/tmp/ipykernel_2195305/3629608360.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.left = [torch.tensor(row[0], dtype=torch.int64) for row in data]\n",
      "/tmp/ipykernel_2195305/3629608360.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.right = [torch.tensor(row[1], dtype=torch.int64) for row in data]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dbf474bf4694e88bd859f738b4c74b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2195305/853187508.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(y, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Losses: train - 0.159, test - 0.470\n",
      "\n",
      "Losses: train - 0.276, test - 0.469\n",
      "\n",
      "Losses: train - 0.224, test - 0.477\n",
      "\n",
      "Losses: train - 0.150, test - 0.485\n",
      "\n",
      "Losses: train - 0.091, test - 0.479\n",
      "\n",
      "Losses: train - 0.134, test - 0.484\n",
      "\n",
      "Losses: train - 0.137, test - 0.486\n",
      "\n",
      "Losses: train - 0.141, test - 0.484\n",
      "\n",
      "Losses: train - 0.116, test - 0.485\n",
      "\n",
      "Losses: train - 0.165, test - 0.490\n",
      "\n",
      "Losses: train - 0.092, test - 0.484\n",
      "\n",
      "Losses: train - 0.113, test - 0.483\n",
      "\n",
      "Losses: train - 0.102, test - 0.486\n",
      "\n",
      "Losses: train - 0.090, test - 0.488\n",
      "\n",
      "Losses: train - 0.140, test - 0.487\n",
      "\n",
      "Losses: train - 0.183, test - 0.485\n",
      "\n",
      "Losses: train - 0.076, test - 0.488\n",
      "\n",
      "Losses: train - 0.071, test - 0.489\n",
      "\n",
      "Losses: train - 0.084, test - 0.489\n",
      "\n",
      "Losses: train - 0.055, test - 0.491\n",
      "\n",
      "Losses: train - 0.095, test - 0.488\n",
      "\n",
      "Losses: train - 0.063, test - 0.486\n",
      "\n",
      "Losses: train - 0.074, test - 0.487\n",
      "\n",
      "Losses: train - 0.097, test - 0.483\n",
      "\n",
      "Losses: train - 0.070, test - 0.485\n",
      "\n",
      "Losses: train - 0.099, test - 0.486\n",
      "\n",
      "Losses: train - 0.075, test - 0.487\n",
      "\n",
      "Losses: train - 0.106, test - 0.487\n",
      "\n",
      "Losses: train - 0.089, test - 0.489\n",
      "\n",
      "Losses: train - 0.087, test - 0.487\n",
      "logloss:  2.7905268200960567\n",
      "accuracy:  0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2195305/3412259436.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(y, dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "Siamese_pipeline(data=train_modern, test_data=test_modern, labels=['f', 'm'], column='gender', wv=wv)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
