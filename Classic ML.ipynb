{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da89090c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0ee295",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7402a2db",
   "metadata": {},
   "source": [
    "## Doyle & Christie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39ab588c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_Doyle_Christie():\n",
    "    data = pd.read_csv(\"Doyle_Christie_dataset/train.csv\")\n",
    "    data = data.drop(columns=['Unnamed: 0',])\n",
    "    data['labels'] = data['author'].apply(lambda x: 0 if x == 'Doyle' else 1)\n",
    "    \n",
    "    test_data = pd.read_csv(\"Doyle_Christie_dataset/test.csv\")\n",
    "    test_data = test_data.drop(columns=['Unnamed: 0',])\n",
    "    test_data['labels'] = test_data['author'].apply(lambda x: 0 if x == 'Doyle' else 1)\n",
    "    \n",
    "    return data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f00f853",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dc, test_dc = process_Doyle_Christie()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1359def",
   "metadata": {},
   "source": [
    "## Letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14005b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_Letters():\n",
    "    old_eng = pd.read_csv('old_english_dataset.csv')\n",
    "    old_eng = old_eng.drop(columns=['Unnamed: 0',])\n",
    "    old_eng['labels'] = old_eng['gender'].apply(lambda x: 0 if x == 'f' else 1)\n",
    "    \n",
    "    equal = old_eng[old_eng['labels'] == 1].sample(n = 2806)\n",
    "    train_old_eng = pd.concat([equal, old_eng[old_eng['labels'] == 0]], ignore_index=True)\n",
    "    \n",
    "    women = train_old_eng[train_old_eng['labels'] == 0]\n",
    "    men = train_old_eng[train_old_eng['labels'] == 1]\n",
    "    \n",
    "    test_women = women.sample(frac=0.1)\n",
    "    train_women = women.drop(test_women.index)\n",
    "    test_men = men.sample(frac=0.1)\n",
    "    train_men = men.drop(test_men.index)\n",
    "    \n",
    "    train_old_eng = pd.concat([train_women, train_men], ignore_index=True)\n",
    "    test_old_eng = pd.concat([test_women, test_men], ignore_index=True)\n",
    "    \n",
    "    return train_old_eng, test_old_eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb27d751",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_letters, test_letters = process_Letters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8384db5",
   "metadata": {},
   "source": [
    "## Modern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8869a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_Modern():\n",
    "    data = pd.read_csv(\"Modern_dataset/train.csv\")\n",
    "    data = data.drop(columns=['Unnamed: 0',])\n",
    "    data['labels'] = data['gender'].apply(lambda x: 0 if x == 'f' else 1)\n",
    "    \n",
    "    train_data = pd.concat([data[data['labels'] == 1].sample(n=30941), data[data['labels']==0]], \n",
    "                       ignore_index=True)\n",
    "    \n",
    "    test = pd.read_csv(\"Modern_dataset/test.csv\")\n",
    "    test = test.drop(columns=['Unnamed: 0',])\n",
    "    test['labels'] = test['gender'].apply(lambda x: 0 if x == 'f' else 1)\n",
    "    \n",
    "    test_data = pd.concat([test[test['labels'] == 0].sample(n=5000), test[test['labels'] == 1].sample(n=5000)], \n",
    "                      ignore_index=True)\n",
    "    \n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d719b2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_modern, test_modern = process_Modern()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd602f6e",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0d9acc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_logistic_classify(X_tr, y_tr, X_test, y_test, description):\n",
    "    model = LogisticRegression().fit(X_tr, y_tr)\n",
    "    score = model.score(X_test, y_test)\n",
    "    print('Logreg + ', description)\n",
    "    print('Test Score: ', score)\n",
    "    print()\n",
    "    return model\n",
    "\n",
    "def svm_classify(X_tr, y_tr, X_test, y_test, description):\n",
    "    model = SVC().fit(X_tr, y_tr)\n",
    "    score = model.score(X_test, y_test)\n",
    "    print('SVM + ', description)\n",
    "    print('Test Score: ', score)\n",
    "    print()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3bc933be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ML_pipeline(data, test_data):\n",
    "    bow_vect = CountVectorizer()\n",
    "    bow_train = bow_vect.fit_transform(data['sentence'])\n",
    "    bow_test = bow_vect.transform(test_data['sentence'])\n",
    "    \n",
    "    bow_model = simple_logistic_classify(X_tr = bow_train, \n",
    "                                     y_tr = data['labels'],\n",
    "                                     X_test = bow_test, \n",
    "                                     y_test = test_data['labels'], \n",
    "                                     description='bag of words')\n",
    "    \n",
    "    tfidf_vect = TfidfVectorizer()\n",
    "    tfidf_train = tfidf_vect.fit_transform(data['sentence'])\n",
    "    tfidf_test = tfidf_vect.transform(test_data['sentence'])\n",
    "    \n",
    "    tfidf_model = simple_logistic_classify(X_tr = tfidf_train, \n",
    "                                       y_tr = data['labels'],\n",
    "                                       X_test = tfidf_test,\n",
    "                                       y_test = test_data['labels'], \n",
    "                                       description='tf-idf')\n",
    "    \n",
    "    svm_model = svm_classify(X_tr = tfidf_train, \n",
    "                           y_tr = data['labels'],\n",
    "                           X_test = tfidf_test,\n",
    "                           y_test = test_data['labels'], \n",
    "                            description='tf-idf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "effc378d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/antonauna/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logreg +  bag of words\n",
      "Test Score:  0.7415\n",
      "\n",
      "Logreg +  tf-idf\n",
      "Test Score:  0.7455\n",
      "\n",
      "SVM +  tf-idf\n",
      "Test Score:  0.757\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ML_pipeline(data=train_dc, test_data=test_dc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d8099a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/antonauna/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logreg +  bag of words\n",
      "Test Score:  0.8594306049822064\n",
      "\n",
      "Logreg +  tf-idf\n",
      "Test Score:  0.8665480427046264\n",
      "\n",
      "SVM +  tf-idf\n",
      "Test Score:  0.8718861209964412\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ML_pipeline(data=train_letters, test_data=test_letters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38c0a152",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/antonauna/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logreg +  bag of words\n",
      "Test Score:  0.5192\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/antonauna/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logreg +  tf-idf\n",
      "Test Score:  0.525\n",
      "\n",
      "SVM +  tf-idf\n",
      "Test Score:  0.5229\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ML_pipeline(data=train_modern, test_data=test_modern)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
